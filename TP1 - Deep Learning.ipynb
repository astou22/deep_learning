{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer\n",
    "vision and natural language processing, primarily developed by Facebook's AI Research lab (FAIR).\n",
    "It is free and open-source software released under the Modified BSD license. Although the Python interface is \n",
    "more polished and the primary focus of development, PyTorch also has a C++ interface.\n",
    "\n",
    "A number of pieces of Deep Learning software are built on top of PyTorch, including Tesla Autopilot,Uber's Pyro, \n",
    "HuggingFace's Transformers, PyTorch Lightning, and Catalyst.\n",
    "\n",
    "PyTorch provides two high-level features:\n",
    "    \n",
    "    1. Tensor computing (like NumPy) with strong acceleration via graphics processing units (GPU) \n",
    "    \n",
    "    2. Deep neural networks built on a tape-based automatic differentiation system \n",
    "    \n",
    "![](profiler.png)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:green '> Anaconda : To install PyTorch via Anaconda, use the following conda command: </span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue '> Pip : To install PyTorch via pip, use the following command: </span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification : To ensure that PyTorch was installed correctly, we can verify the installation by importing the torch module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:green'>\n",
    "At its core, PyTorch is a library for processing tensors. A tensor is a number, vector, matrix, or any n-dimensional array. Let's create a tensor with a single number.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a scalar (zero-dimensional tensor)\n",
    "t0 = torch.tensor(2.)\n",
    "t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red'> \n",
    "\"2.\" is a shorthand for 2.0. It is used to indicate to Python (and PyTorch) that you want to create a floating-point number. We can verify this by checking the dtype attribute of our tensor.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:green'> Let's try creating more complex tensors. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a vector (one-dimensional tensor)\n",
    "t1 = torch.tensor([1., 2, 3, 4])\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a matrix (two-dimensional tensor) t2\n",
    "t2 = torch.tensor([[1., 2],[3, 4]])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 2.0000, 3.0000],\n",
       "        [4.0000, 5.0000, 6.0000],\n",
       "        [5.8000, 8.9000, 0.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a 3-dimensional tensor t3\n",
    "t3 = torch.tensor([[1., 2, 3,],[4,5.,6.],[5.8,8.9,0]])\n",
    "t3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:green'>\n",
    "Tensors can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the .shape property of a tensor.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t0)\n",
    "t0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the size of t1\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the size of t2\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the size of t3\n",
    "t3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red '> Note that it's not possible to create tensors with an improper shape. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix (2-dimensional tensor)\n",
    "#t4 = torch.tensor([[ 5.,6, 11], [7, 8],[9, 10]])\n",
    "#t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red '> A ValueError is thrown because the lengths of the rows [5., 6, 11] and [7, 8] don't match. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tensor operations and gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:green'> We can combine tensors with the usual arithmetic operations. Let's look at an example: </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors.\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "x, w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:green'> We've created three tensors: x, w, and b, all numbers. w and b have an additional parameter requires_grad set to True. We'll see what it does in just a moment.\n",
    "Let's create a new tensor y by combining these tensors. </span> $y=w*x+b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the Arithmetic operation here \n",
    "y=w*x+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, y is a tensor with the value 4 * 3 + 5 = 17. What makes PyTorch unique is that we can automatically compute the derivative of y w.r.t. the tensors that have requires_grad set to True i.e. w and b. This feature of PyTorch is called autograd (automatic gradients).\n",
    "\n",
    "To compute the derivatives, we can invoke the .backward method on our result y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.backward of tensor(17., grad_fn=<AddBackward0>)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute derivatives  using the backward \n",
    "y.backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivatives of y with respect to the input tensors are stored in the .grad property of the respective tensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx:  None\n",
      "dy/db:  None\n",
      "dy/dw:  None\n"
     ]
    }
   ],
   "source": [
    "# print the  Display gradients using the grad \n",
    "print(\"dy/dx: \",x.grad)\n",
    "print(\"dy/db: \",b.grad)\n",
    "print(\"dy/dw: \",w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, dy/dw has the same value as x, i.e., 3, and dy/db has the value 1. Note that x.grad is None because x doesn't have requires_grad set to True.\n",
    "\n",
    "The \"grad\" in w.grad is short for gradient, which is another term for derivative. The term gradient is primarily used while dealing with vectors and matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Tensor functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from arithmetic operations, the torch module also contains many functions for creating and manipulating tensors. Let's look at some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\TensorFactories.cpp:361: UserWarning: Deprecation warning: In a future PyTorch release torch.full will no longer return tensors of floating dtype by default. Instead, a bool fill_value will return a tensor of torch.bool dtype, and an integral fill_value will return a tensor of torch.long dtype. Set the optional `dtype` or `out` arguments to suppress this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[42., 42.],\n",
       "        [42., 42.],\n",
       "        [42., 42.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with a fixed value for every element\n",
    "t6 = torch.full((3, 2), 42)\n",
    "t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create other tensors with the tensor fuctions \n",
    "t7 = torch.full((3, 3), 3)\n",
    "t7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor filled with the scalar value 0, with the shape defined by the variable argument size. \n",
    "#(using the function zeros)\n",
    "t8=torch.zeros(5,dtype=float)\n",
    "t8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate two tensors with compatible shapes t3 and t6 in t7 using the function of the concatenation \n",
    "t9=torch.cat((t3,t6,t7),1)\n",
    "#on ne peut pas faire de concatenation avec des tensors de dimensions différents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the sin of each element of a tensor t8\n",
    "torch.sin(t8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the shape of t8\n",
    "t8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the shape of a tensor t8 in t9\n",
    "#torch.reshape(t8,t9.shape)\n",
    "#le changement de dimension depend de celle des deux tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a a 2-D tensor with ones on the diagonal and zeros elsewhere using the function eye of pytorch \n",
    "\n",
    "t10=torch.eye(2)\n",
    "t10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0.],\n",
       "         [0., 1.]]),)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splits the tensor into chunks. Each chunk is a view of the original tensor using the function split of pytorch \n",
    "torch.split(t10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Expects input to be <= 2-D tensor and transposes dimensions 0 and 1.0-D and 1-D tensors are returned as is.\n",
    "#When input is a 2-D tensor this is equivalent to transpose(input, 0, 1).\n",
    "torch.transpose(t10,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a tensor filled with random numbers from a uniform distribution on the interval [0, 1)[0,1)\n",
    "t11=torch.rand(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computes the absolute value of each element in input using the abs tensor fucyion \n",
    "torch.abs(t11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the scalar other to each element of the input input and returns a new resulting tensor.\n",
    "t11+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computes the fractional portion of each element in input.\n",
    "torch.frac(t11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns a new tensor with the exponential of the elements of the input tensor input.\n",
    "torch.exp(t11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about tensor operations here: https://pytorch.org/docs/stable/torch.html . Experiment with some more tensor functions and operations using the empty cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interoperability with Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy is a popular open-source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays and has a vast ecosystem of supporting libraries, including:\n",
    "\n",
    "Pandas for file I/O and data analysis\n",
    "\n",
    "Matplotlib for plotting and visualization\n",
    "\n",
    "OpenCV for image and video processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of reinventing the wheel, PyTorch interoperates well with Numpy to leverage its existing ecosystem of tools and libraries.\n",
    "\n",
    "Here's how we create an array in Numpy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create a random numpy matrix \n",
    "n1_=np.random.randint(1, 5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert a Numpy array to a PyTorch tensor using torch.from_numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a numpy matrix to a tensor \n",
    "t1_=torch.Tensor(list(n1_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the numpy array and torch tensor have similar data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table numpy  [1 1 1 3 1 1 4 2 2 3]\n",
      "table torch  tensor([1., 1., 1., 3., 1., 1., 4., 2., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# verify the element type \n",
    "print(\"table numpy \",n1_)\n",
    "print(\"table torch \",t1_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert a PyTorch tensor to a Numpy array using the .numpy method of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 3., 1., 1., 4., 2., 2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert a torch tensor to a numpy array\n",
    "n1__=t1_.numpy()\n",
    "n1__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interoperability between PyTorch and Numpy is essential because most datasets you'll work with will likely be read and preprocessed as Numpy arrays.\n",
    "\n",
    "You might wonder why we need a library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:\n",
    "\n",
    "Autograd: The ability to automatically compute gradients for tensor operations is essential for training deep learning models.\n",
    "GPU support: While working with massive datasets and large models, PyTorch tensor operations can be performed efficiently using a Graphics Processing Unit (GPU). Computations that might typically take hours can be completed within minutes using GPUs.\n",
    "We'll leverage both these features of PyTorch extensively in in the the coming sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience and visualization, we will only use two features in this notebook, so we are still able to plot them together with the target class and decision boundary\n",
    "\n",
    "First we will create some artificial data:\n",
    "\n",
    "-\n",
    "m\n",
    "1\n",
    "=\n",
    "10\n",
    " examples for class 0 -\n",
    "m\n",
    "2\n",
    "=\n",
    "15\n",
    " examples for class 1 -\n",
    "n\n",
    "=\n",
    "2\n",
    " features for each example\n",
    "\n",
    "No exercise yet, just execute the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = 10\n",
    "m2 = 15\n",
    "m = m1 + m2\n",
    "n = 2\n",
    "X = np.ndarray((m,n))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros((m))\n",
    "y[m1:] = y[m1:] + 1.0\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### complet the code  to generate linearly sperable data\n",
    "def x2_function_class_0(x):\n",
    "    return x*2+3\n",
    "\n",
    "def x2_function_class_1(x):\n",
    "     return x*4-4\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### complet the code to generate NOT linearly sperable data\n",
    "def x2_function_class_0(x):\n",
    "        return np.sin(x)-7\n",
    "def x2_function_class_1(x):\n",
    "        return np.sin(x)+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_min = -5\n",
    "x1_max = +5\n",
    "\n",
    "X[:m1,0] = np.linspace(x1_min, x1_max, m1)\n",
    "X[m1:,0] = np.linspace(x1_min+0.5, x1_max-0.2, m2)\n",
    "# update the X[:m1,0]  and X[m1:,0] using the predefined functions x2_function_class_0 x2_function_class_1\n",
    "X[:m1,1]=x2_function_class_0(X[:m1,0])\n",
    "X[m1:,0]=x2_function_class_1(X[m1:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data():\n",
    "    plt.scatter(X[:m1,0], X[:m1,1], alpha=0.5, label='class 0 train data')\n",
    "    # do the same for class 1 train data'\n",
    "\n",
    "    plt.plot(x1_line, x2_line_class_0, alpha=0.2, label='class 0 true target func')\n",
    "    # do the same for class 1 true target func\n",
    "    plt.legend(loc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1_line = np.linspace(x1_min, x1_max, 100)\n",
    "# define the linear function using the the prefdefined functions\n",
    "x2_line_class_0 = x2_function_class_0(x1_line)\n",
    "x2_line_class_1 = x2_function_class_1(x1_line)  \n",
    "\n",
    "# polt the data \n",
    "plot_data()\n",
    "#plot_data(x2_line_class_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the Data to torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert  the X and Y to tensors \n",
    "X=torch.Tensor(list(X))\n",
    "y=torch.Tensor(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape  torch.Size([25, 2])\n",
      "y shape  torch.Size([25])\n"
     ]
    }
   ],
   "source": [
    "# print  the shapes \n",
    "print(\"X shape \",X.shape)\n",
    "print(\"y shape \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy is a great framework, but it cannot utilize GPUs to accelerate its numerical computations. For modern deep neural networks, GPUs often provide speedups of 50x or greater, so unfortunately numpy won’t be enough for modern deep learning.\n",
    "\n",
    "Here we introduce the most fundamental PyTorch concept: the Tensor. A PyTorch Tensor is conceptually identical to a numpy array: a Tensor is an n-dimensional array, and PyTorch provides many functions for operating on these Tensors. Behind the scenes, Tensors can keep track of a computational graph and gradients, but they’re also useful as a generic tool for scientific computing.\n",
    "\n",
    "Also unlike numpy, PyTorch Tensors can utilize GPUs to accelerate their numeric computations. To run a PyTorch Tensor on GPU, you simply need to specify the correct device.\n",
    "\n",
    "Here we use PyTorch Tensors to fit a third order polynomial to sine function. Like the numpy example above we need to manually implement the forward and backward passes through the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 23506\n",
      "199 23506\n",
      "299 23506\n",
      "399 23506\n",
      "499 23506\n",
      "599 23506\n",
      "699 23506\n",
      "799 23506\n",
      "899 23506\n",
      "999 23506\n",
      "1099 23506\n",
      "1199 23506\n",
      "1299 23506\n",
      "1399 23506\n",
      "1499 23506\n",
      "1599 23506\n",
      "1699 23506\n",
      "1799 23506\n",
      "1899 23506\n",
      "1999 23506\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-9f050d0e7c2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Update weights using gradient descent of a, b, c, d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# Create random input and output data using the tensor functions x and y \n",
    "x=np.random.randint(1, 5, 10)\n",
    "y=np.random.randint(1, 2, 10)\n",
    "\n",
    "# Randomly initialize weights a, b ,c \n",
    "a=np.random.randint(1, 5, 10)\n",
    "b=np.random.randint(1, 2, 10)\n",
    "c=np.random.randint(1, 2, 10)\n",
    "d=np.random.randint(1, 2, 10)\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.power(y_pred - y,2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    \n",
    "\n",
    "    # Update weights using gradient descent of a, b, c, d \n",
    "    \n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import math\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\")  # Uncomment this to run on GPU\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "# By default, requires_grad=False, which indicates that we do not need to\n",
    "# compute gradients with respect to these Tensors during the backward pass.\n",
    "\n",
    "\n",
    "\n",
    "# Create random Tensors for weights. For a third order polynomial, we need\n",
    "# 4 weights: y = a + b x + c x^2 + d x^3\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y using operations on Tensors.\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss using operations on Tensors.\n",
    "    # Now loss is a Tensor of shape (1,)\n",
    "    # loss.item() gets the scalar value held in the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call a.grad, b.grad. c.grad and d.grad will be Tensors holding\n",
    "    # the gradient of the loss with respect to a, b, c, d respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this\n",
    "    # in autograd.\n",
    "\n",
    "        \n",
    "    # Manually zero the gradients after updating weights\n",
    "      \n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch: Defining new autograd functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Under the hood, each primitive autograd operator is really two functions that operate on Tensors. The forward function computes output Tensors from input Tensors. The backward function receives the gradient of the output Tensors with respect to some scalar value, and computes the gradient of the input Tensors with respect to that same scalar value.\n",
    "\n",
    "In PyTorch we can easily define our own autograd operator by defining a subclass of torch.autograd.Function and implementing the forward and backward functions. We can then use our new autograd operator by constructing an instance and calling it like a function, passing Tensors containing input data.\n",
    "\n",
    "In this example we define our model as $y=a+bP_3(c+dx)$ instead of y=a+bx+cx^2+dx^3, where $P_3(x)=1/2(5x^3−3x)$ is the Legendre polynomial of degree three. We write our own custom autograd function for computing forward and backward of P3, and use it to implement our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "class LegendrePolynomial3(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        return grad_output * 1.5 * (5 * input ** 2 - 1)\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\")  # Uncomment this to run on GPU\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "# By default, requires_grad=False, which indicates that we do not need to\n",
    "# compute gradients with respect to these Tensors during the backward pass.\n",
    "\n",
    "#......\n",
    "\n",
    "# Create random Tensors for weights. For this example, we need\n",
    "# 4 weights: y = a + b * P3(c + d * x), these weights need to be initialized\n",
    "# not too far from the correct result to ensure convergence.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "\n",
    "\n",
    "#The weights a, b, c, d\n",
    "learning_rate = 5e-6\n",
    "for t in range(2000):\n",
    "    # To apply our Function, we use Function.apply method. We alias this as 'P3'.\n",
    "    P3 = LegendrePolynomial3.apply\n",
    "\n",
    "    # Forward pass: compute predicted y using operations; we compute\n",
    "    # P3 using our custom autograd operation.\n",
    "    y_pred = a + b * P3(c + d * x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "\n",
    "\n",
    "    # Manually zero the gradients after updating weights\n",
    "      \n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of data transformation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Library\n",
    "PyTorch code is simple. It is easy to understand, and you use the library instantly. For example, take a look at the code snippet below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize our data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# define x and y using the numpuy library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array to tensor in shape of input size x and y \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll set up TensorBoard, importing tensorboard from torch.utils and defining a SummaryWriter, our key object for writing information to TensorBoard.\n",
    "\n",
    "TensorBoard: TensorFlow's visualization toolkit\n",
    "\n",
    "TensorBoard provides the visualization and tooling needed for machine learning experimentation:\n",
    " ->Tracking and visualizing metrics such as loss and accuracy\n",
    " \n",
    " ->Visualizing the model graph (ops and layers)\n",
    " \n",
    " ->Viewing histograms of weights, biases, or other tensors as they change over time\n",
    " \n",
    " ->Projecting embeddings to a lower dimensional space\n",
    " \n",
    " ->Displaying images, text, and audio data\n",
    " \n",
    " ->Profiling TensorFlow programs\n",
    " \n",
    "And much more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZING MODELS, DATA, AND TRAINING WITH TENSORBOARD\n",
    "In the 60 Minute Blitz, we show you how to load in data, feed it through a model we define as a subclass of nn.Module, train this model on training data, and test it on test data. To see what’s happening, we print out some statistics as the model is training to get a sense for whether training is progressing. However, we can do much better than that: PyTorch integrates with TensorBoard, a tool designed for visualizing the results of neural network training runs. This tutorial illustrates some of its functionality, using the Fashion-MNIST dataset which can be read into PyTorch using torchvision.datasets.\n",
    "\n",
    "In this tutorial, we’ll learn how to:\n",
    "\n",
    "    Read in data and with appropriate transforms (nearly identical to the prior tutorial).\n",
    "    \n",
    "    Set up TensorBoard.\n",
    "    \n",
    "    Write to TensorBoard.\n",
    "\n",
    "    Inspect a model architecture using TensorBoard.\n",
    "    \n",
    "    Use TensorBoard to create interactive versions of the visualizations we created in last tutorial, with less code\n",
    "    Specifically, on point #5, we’ll see:\n",
    "\n",
    "A couple of ways to inspect our training data\n",
    "How to track our model’s performance as it trains\n",
    "How to assess our model’s performance once it is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll define a similar model architecture from that tutorial, making only minor modifications to account for the fact that the images are now one channel instead of three and 28x28 instead of 32x32:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll define the same optimizer and criterion from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TensorBoard setup\n",
    "Now we’ll set up TensorBoard, importing tensorboard from torch.utils and defining a SummaryWriter, our key object for writing information to TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this line alone creates a runs/fashion_mnist_experiment_1 folder.\n",
    "\n",
    "# 2. Writing to TensorBoard\n",
    "\n",
    "Now let’s write an image to our TensorBoard - specifically, a grid - using make_grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know how to use TensorBoard! This example, however, could be done in a Jupyter Notebook - where TensorBoard really excels is in creating interactive visualizations. We’ll cover one of those next, and several more by the end of the tutorial.\n",
    "\n",
    "# 3. Inspect the model using TensorBoard\n",
    "One of TensorBoard’s strengths is its ability to visualize complex model structures. Let’s visualize the model we built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upon refreshing TensorBoard you should see a “Graphs” tab that looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and double click on “Net” to see it expand, seeing a detailed view of the individual operations that make up the model.\n",
    "\n",
    "TensorBoard has a very handy feature for visualizing high dimensional data such as image data in a lower dimensional space; we’ll cover this next.\n",
    "\n",
    "# 4. Adding a “Projector” to TensorBoard\n",
    "We can visualize the lower dimensional representation of higher dimensional data via the add_embedding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in the “Projector” tab of TensorBoard, you can see these 100 images - each of which is 784 dimensional - projected down into three dimensional space. Furthermore, this is interactive: you can click and drag to rotate the three dimensional projection. Finally, a couple of tips to make the visualization easier to see: select “color: label” on the top left, as well as enabling “night mode”, which will make the images easier to see since their background is white:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ve thoroughly inspected our data, let’s show how TensorBoard can make tracking model training and evaluation clearer, starting with training.\n",
    "\n",
    "# 5. Tracking model training with TensorBoard\n",
    "In the previous example, we simply printed the model’s running loss every 2000 iterations. Now, we’ll instead log the running loss to TensorBoard, along with a view into the predictions the model is making via the plot_classes_preds function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let’s train the model using the same model training code from the prior tutorial, but writing results to TensorBoard every 1000 batches instead of printing to console; this is done using the add_scalar function.\n",
    "\n",
    "In addition, as we train, we’ll generate an image showing the model’s predictions vs. the actual results on the four images included in that batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "vectors = np.array([[0,0,1], [0,1,0], [1,0,0], [1,1,1]])\n",
    "metadata = ['001', '010', '100', '111']  # labels\n",
    "writer = SummaryWriter()\n",
    "writer.add_embedding(vectors, metadata)\n",
    "writer.close()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs'''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
